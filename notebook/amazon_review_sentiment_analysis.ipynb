{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "view-in-github",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tikendraw/Amazon-review-sentiment-analysis/blob/main/amazon-review-sentiment-analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c16cfc6",
      "metadata": {
        "id": "1c16cfc6"
      },
      "source": [
        "# Amazon Reviews for Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fac0c72",
      "metadata": {
        "id": "3fac0c72"
      },
      "source": [
        "## Objective\n",
        "\n",
        "Here we will be Building ML and DL models to predict the Polarity of reviews.\n",
        "We will be performing series of experiments with different models to achieve the best classification metrics.(while not abusing the machine we have)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ec49b73",
      "metadata": {
        "id": "8ec49b73"
      },
      "source": [
        "## About Dataset\n",
        "[Dataset here](https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews)\n",
        "\n",
        "\n",
        "### OVERVIEW\n",
        "Contains 34,686,770 Amazon reviews from 6,643,669 users on 2,441,053 products, from the Stanford Network Analysis Project (SNAP). This subset contains 1,800,000 training samples and 200,000 testing samples in each polarity sentiment.\n",
        "\n",
        "### ORIGIN\n",
        "The Amazon reviews dataset consists of reviews from amazon. The data span a period of 18 years, including ~35 million reviews up to March 2013. Reviews include product and user information, ratings, and a plaintext review. For more information, please refer to the following paper: J. McAuley and J. Leskovec. Hidden factors and hidden topics: understanding rating dimensions with review text. RecSys, 2013.\n",
        "\n",
        "### DESCRIPTION\n",
        "The Amazon reviews polarity dataset is constructed by taking review score 1 and 2 as negative, and 4 and 5 as positive. Samples of score 3 is ignored. In the dataset, class 1 is the negative and class 2 is the positive. Each class has 1,800,000 training samples and 200,000 testing samples.\n",
        "\n",
        "If you need help extracting the train.csv and test.csv files check out the starter code.\n",
        "\n",
        "The files train.csv and test.csv contain all the training samples as comma-separated values.\n",
        "\n",
        "The CSVs contain polarity, title, text. These 3 columns in them, correspond to class index (1 or 2), review title and review text.\n",
        "\n",
        "polarity - 1 for negative and 2 for positive\n",
        "title - review heading\n",
        "text - review body\n",
        "The review title and text are escaped using double quotes (\"), and any internal double quote is escaped by 2 double quotes (\"\"). New lines are escaped by a backslash followed with an \"n\" character, that is \"\\n\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29a25034",
      "metadata": {
        "id": "29a25034"
      },
      "outputs": [],
      "source": [
        "# ! git clone https://github.com/tikendraw/funcyou.git -q\n",
        "# ! pip install funcyou/\n",
        "# ! rm -rf funcyou\n",
        "# ! pip install tensorflow_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8e4GevPRvy90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e4GevPRvy90",
        "outputId": "12f1610d-50cb-48a3-f63a-827f88e5868a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: /home/t/miniconda3/envs/deep/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.4/118.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3f06a868",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f06a868",
        "outputId": "f4299411-6822-4e5e-d503-bdca5d407d90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-01 07:49:04.139252: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-01 07:49:05.478811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tf version:  2.12.1\n",
            "GPU:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-01 07:49:08.897788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-09-01 07:49:09.060684: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "import tarfile\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import contractions\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import check_random_state\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, TextVectorization\n",
        "from tensorflow_hub import KerasLayer\n",
        "\n",
        "try:\n",
        "    import funcyou\n",
        "except ImportError:\n",
        "    # Install funcyou\n",
        "    !pip install git+https://github.com/tikendraw/funcyou.git@main\n",
        "\n",
        "# Importing useful functions from funcyou\n",
        "from funcyou.dataset import download_kaggle_resource\n",
        "from funcyou.plot import distplot_axis, plot_history, compare_histories\n",
        "from funcyou.preprocessing.text import IntegerVectorizer\n",
        "from funcyou.sklearn.metrics import calculate_results\n",
        "\n",
        "print('Tf version:', tf.__version__)\n",
        "print('GPU:', len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "750e2f16",
      "metadata": {
        "id": "750e2f16"
      },
      "outputs": [],
      "source": [
        "def set_global_seed(seed):\n",
        "    tf.random.set_seed(seed)\n",
        "    global random_state\n",
        "    random_state = check_random_state(seed)\n",
        "\n",
        "\n",
        "# Set the seed value\n",
        "SEED = 42 # should be same as seed in config file\n",
        "\n",
        "# Call the function to set the seeds\n",
        "set_global_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "JoiHXi71fwLG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoiHXi71fwLG",
        "outputId": "33631325-62e7-4c93-e8c0-fae6755d1097"
      },
      "outputs": [],
      "source": [
        "# download and enter the repo to access other files\n",
        "\n",
        "colab = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if colab:\n",
        "    os.system('git clone https://github.com/tikendraw/Amazon-review-sentiment-analysis.git')\n",
        "\n",
        "    if os.getcwd() != '/content/Amazon-review-sentiment-analysis/notebook':\n",
        "        os.chdir('Amazon-review-sentiment-analysis/notebook')\n",
        "    print('Current working directory: ',os.getcwd())\n",
        "    \n",
        "    \n",
        "    # load google drive \n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "35cec4d3",
      "metadata": {
        "id": "35cec4d3"
      },
      "outputs": [],
      "source": [
        "cur_dir = Path(os.getcwd())\n",
        "model_dir = Path(os.getcwd()).parent /'model'\n",
        "data_dir = Path(os.getcwd()).parent /'dataset'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "db919e15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db919e15",
        "outputId": "bc0d1453-539c-402c-9327-8a3942041b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/t/aproject/Amazon-review-sentiment-analysis/notebook\n",
            "/home/t/aproject/Amazon-review-sentiment-analysis/model\n",
            "/home/t/aproject/Amazon-review-sentiment-analysis/dataset\n"
          ]
        }
      ],
      "source": [
        "print(cur_dir)\n",
        "print(model_dir)\n",
        "print(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "NX4nMoR_KGax",
      "metadata": {
        "id": "NX4nMoR_KGax"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "Ao1oDevPpp3z",
      "metadata": {
        "id": "Ao1oDevPpp3z"
      },
      "outputs": [],
      "source": [
        "# Download the data if you don't have locally\n",
        "dataset_url = 'https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "XSkPxCeYqyQS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSkPxCeYqyQS",
        "outputId": "3c7f2874-a020-49a7-e364-71c0b70aab1c"
      },
      "outputs": [],
      "source": [
        "if colab:\n",
        "    download_kaggle_resource(dataset_url, data_dir, kaggle_json_path = '/content/kaggle.json')\n",
        "\n",
        "    from zipfile import ZipFile\n",
        "    with ZipFile(data_dir/'amazon-reviews'/'amazon-reviews.zip') as f:\n",
        "        f.extractall(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b0fa02",
      "metadata": {
        "id": "a5b0fa02"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d2fc7d74",
      "metadata": {
        "id": "d2fc7d74"
      },
      "outputs": [],
      "source": [
        "#reading data\n",
        "df = pl.read_csv(data_dir/'train.csv',new_columns = ['polarity', 'title','text'])  # gives TextFileReader, which is iterable with chunks of 1000 rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "132384b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "132384b1",
        "outputId": "47d1bd26-eca1-4e12-bbd1-986af0d9b279"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (9, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>describe</th><th>polarity</th><th>title</th><th>text</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>3.599999e6</td><td>&quot;3599999&quot;</td><td>&quot;3599999&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>1.5</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>0.5</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>&quot;&quot;</td><td>&quot;\u0003this is the b…</td></tr><tr><td>&quot;max&quot;</td><td>2.0</td><td>&quot;♦ LOVE IT ♦&quot;</td><td>&quot;…were Marvin a…</td></tr><tr><td>&quot;median&quot;</td><td>1.0</td><td>null</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>1.0</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>2.0</td><td>null</td><td>null</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (9, 4)\n",
              "┌────────────┬────────────┬─────────────┬───────────────────────────────────┐\n",
              "│ describe   ┆ polarity   ┆ title       ┆ text                              │\n",
              "│ ---        ┆ ---        ┆ ---         ┆ ---                               │\n",
              "│ str        ┆ f64        ┆ str         ┆ str                               │\n",
              "╞════════════╪════════════╪═════════════╪═══════════════════════════════════╡\n",
              "│ count      ┆ 3.599999e6 ┆ 3599999     ┆ 3599999                           │\n",
              "│ null_count ┆ 0.0        ┆ 0           ┆ 0                                 │\n",
              "│ mean       ┆ 1.5        ┆ null        ┆ null                              │\n",
              "│ std        ┆ 0.5        ┆ null        ┆ null                              │\n",
              "│ min        ┆ 1.0        ┆             ┆ \u0003this is the best toy in the wro…  │\n",
              "│ max        ┆ 2.0        ┆ ♦ LOVE IT ♦ ┆ …were Marvin and Tami not the be… │\n",
              "│ median     ┆ 1.0        ┆ null        ┆ null                              │\n",
              "│ 25%        ┆ 1.0        ┆ null        ┆ null                              │\n",
              "│ 75%        ┆ 2.0        ┆ null        ┆ null                              │\n",
              "└────────────┴────────────┴─────────────┴───────────────────────────────────┘"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "Jsn520qsxj6C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "Jsn520qsxj6C",
        "outputId": "c81c2b57-36e2-4503-d97b-7e5b1a711c9e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>polarity</th><th>title</th><th>text</th></tr><tr><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (1, 3)\n",
              "┌──────────┬───────┬──────┐\n",
              "│ polarity ┆ title ┆ text │\n",
              "│ ---      ┆ ---   ┆ ---  │\n",
              "│ u32      ┆ u32   ┆ u32  │\n",
              "╞══════════╪═══════╪══════╡\n",
              "│ 0        ┆ 0     ┆ 0    │\n",
              "└──────────┴───────┴──────┘"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check for nulls and drop if any\n",
        "df.null_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a0ml-HHdxvxo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0ml-HHdxvxo",
        "outputId": "cef37d3f-90dd-454a-e181-ff0980bed5a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#drop nulls\n",
        "df.drop_nulls()\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c672dec5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "c672dec5",
        "outputId": "b0397b20-fab3-46ef-fea3-40c880ae1dde"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>polarity</th><th>counts</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>1</td><td>1800000</td></tr><tr><td>2</td><td>1799999</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (2, 2)\n",
              "┌──────────┬─────────┐\n",
              "│ polarity ┆ counts  │\n",
              "│ ---      ┆ ---     │\n",
              "│ i64      ┆ u32     │\n",
              "╞══════════╪═════════╡\n",
              "│ 1        ┆ 1800000 │\n",
              "│ 2        ┆ 1799999 │\n",
              "└──────────┴─────────┘"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking for classs imbalance\n",
        "df['polarity'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c168d8cf",
      "metadata": {
        "id": "c168d8cf"
      },
      "source": [
        "# We will map the polarity between 0 for negative sentiment to 1 for positive sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f5cac18d",
      "metadata": {
        "id": "f5cac18d"
      },
      "outputs": [],
      "source": [
        "df = df.with_columns([\n",
        "                    pl.col('polarity').apply(lambda x: 0 if x == 1 else 1).alias('polarity')\n",
        "                     ])\n",
        "\n",
        "df = df.with_columns([\n",
        "                     pl.col('polarity').cast(pl.Int16, strict=False).alias('polarity')\n",
        "                     ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "be973a53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "be973a53",
        "outputId": "c4b844ab-d40d-41c8-c457-4598c84c2bcc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>polarity</th><th>title</th><th>text</th></tr><tr><td>i16</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;A Delightful S…</td><td>&quot;Although I hav…</td></tr><tr><td>0</td><td>&quot;Disaster&quot;</td><td>&quot;This system is…</td></tr><tr><td>0</td><td>&quot;Very poor book…</td><td>&quot;This book offe…</td></tr><tr><td>0</td><td>&quot;Amanda has sho…</td><td>&quot;I bought this …</td></tr><tr><td>0</td><td>&quot;Blood and guts…</td><td>&quot;If you liked &quot;…</td></tr><tr><td>1</td><td>&quot;Captures the E…</td><td>&quot;Heartfelt roma…</td></tr><tr><td>0</td><td>&quot;All my Beads j…</td><td>&quot;OMG! This coul…</td></tr><tr><td>0</td><td>&quot;Crappy Program…</td><td>&quot;Apart from the…</td></tr><tr><td>1</td><td>&quot;Why, oh, why..…</td><td>&quot;...Do these gu…</td></tr><tr><td>1</td><td>&quot;new york 40&#x27;s …</td><td>&quot;a newspaper ph…</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (10, 3)\n",
              "┌──────────┬───────────────────────────────────┬───────────────────────────────────┐\n",
              "│ polarity ┆ title                             ┆ text                              │\n",
              "│ ---      ┆ ---                               ┆ ---                               │\n",
              "│ i16      ┆ str                               ┆ str                               │\n",
              "╞══════════╪═══════════════════════════════════╪═══════════════════════════════════╡\n",
              "│ 1        ┆ A Delightful Study of Earl Hamne… ┆ Although I have been extremely f… │\n",
              "│ 0        ┆ Disaster                          ┆ This system is pumped up bigger … │\n",
              "│ 0        ┆ Very poor book with little to of… ┆ This book offers very little to … │\n",
              "│ 0        ┆ Amanda has short-term memory!     ┆ I bought this at TOYS R US for $… │\n",
              "│ …        ┆ …                                 ┆ …                                 │\n",
              "│ 0        ┆ All my Beads just hit the wall    ┆ OMG! This could not be harder to… │\n",
              "│ 0        ┆ Crappy Programming                ┆ Apart from the fact, that it doe… │\n",
              "│ 1        ┆ Why, oh, why...                   ┆ ...Do these guys just keep getti… │\n",
              "│ 1        ┆ new york 40's thru 60's           ┆ a newspaper photographers visual… │\n",
              "└──────────┴───────────────────────────────────┴───────────────────────────────────┘"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de08710a",
      "metadata": {
        "id": "de08710a"
      },
      "source": [
        "## Note: We will be combining text and title columns . makes more sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "26892e90",
      "metadata": {
        "id": "26892e90"
      },
      "outputs": [],
      "source": [
        "df = df.with_columns([\n",
        "    (pl.col('title')+' ' + pl.col('text')).alias('review')\n",
        "])\n",
        "\n",
        "df = df.with_columns([\n",
        "    pl.col('review').str.to_lowercase()\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9f9586d2",
      "metadata": {
        "id": "9f9586d2"
      },
      "outputs": [],
      "source": [
        "# df = df.with_columns([\n",
        "#     pl.col('title').apply(lambda x: len(str(x).split())).alias('title_len'),\n",
        "# ])\n",
        "\n",
        "# df = df.with_columns([\n",
        "#     pl.col('text').apply(lambda x: len(str(x).split())).alias('text_len'),\n",
        "# ])\n",
        "\n",
        "# df = df.with_columns([\n",
        "#     pl.col('review').apply(lambda x: len(str(x).split())).alias('review_len')\n",
        "# ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5d86a82a",
      "metadata": {
        "id": "5d86a82a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# plt.figure(figsize=(15,5))\n",
        "# distplot_axis(df['title_len'].to_numpy())\n",
        "\n",
        "# plt.figure(figsize=(15,5))\n",
        "# distplot_axis(df['text_len'].to_numpy())\n",
        "\n",
        "# plt.figure(figsize=(15,5))\n",
        "# distplot_axis(df['review_len'].to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "419c7412",
      "metadata": {
        "id": "419c7412"
      },
      "outputs": [],
      "source": [
        "df = df.select(['review', 'polarity'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "e0aca943",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "e0aca943",
        "outputId": "5a878c22-45b1-4cdd-c922-8d78cd6b5f53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>review</th><th>polarity</th></tr><tr><td>str</td><td>i16</td></tr></thead><tbody><tr><td>&quot;the best sound…</td><td>1</td></tr><tr><td>&quot;amazing! this …</td><td>1</td></tr><tr><td>&quot;excellent soun…</td><td>1</td></tr><tr><td>&quot;remember, pull…</td><td>1</td></tr><tr><td>&quot;an absolute ma…</td><td>1</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (5, 2)\n",
              "┌───────────────────────────────────┬──────────┐\n",
              "│ review                            ┆ polarity │\n",
              "│ ---                               ┆ ---      │\n",
              "│ str                               ┆ i16      │\n",
              "╞═══════════════════════════════════╪══════════╡\n",
              "│ the best soundtrack ever to anyt… ┆ 1        │\n",
              "│ amazing! this soundtrack is my f… ┆ 1        │\n",
              "│ excellent soundtrack i truly lik… ┆ 1        │\n",
              "│ remember, pull your jaw off the … ┆ 1        │\n",
              "│ an absolute masterpiece i am qui… ┆ 1        │\n",
              "└───────────────────────────────────┴──────────┘"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "23ab7ccb",
      "metadata": {
        "id": "23ab7ccb"
      },
      "outputs": [],
      "source": [
        "df.write_csv(data_dir / 'preprocessed_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "ef9509d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "ef9509d5",
        "outputId": "882bd594-9e93-454d-f070-4a4675e8d9f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>review</th><th>polarity</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;the best sound…</td><td>1</td></tr><tr><td>&quot;amazing! this …</td><td>1</td></tr><tr><td>&quot;excellent soun…</td><td>1</td></tr><tr><td>&quot;remember, pull…</td><td>1</td></tr><tr><td>&quot;an absolute ma…</td><td>1</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (5, 2)\n",
              "┌───────────────────────────────────┬──────────┐\n",
              "│ review                            ┆ polarity │\n",
              "│ ---                               ┆ ---      │\n",
              "│ str                               ┆ i64      │\n",
              "╞═══════════════════════════════════╪══════════╡\n",
              "│ the best soundtrack ever to anyt… ┆ 1        │\n",
              "│ amazing! this soundtrack is my f… ┆ 1        │\n",
              "│ excellent soundtrack i truly lik… ┆ 1        │\n",
              "│ remember, pull your jaw off the … ┆ 1        │\n",
              "│ an absolute masterpiece i am qui… ┆ 1        │\n",
              "└───────────────────────────────────┴──────────┘"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pl.read_csv(data_dir/'preprocessed_df.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4c2a876",
      "metadata": {},
      "source": [
        "## Preprocessing text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "4375da5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Compile the regular expressions outside the function for better performance\n",
        "PUNCTUATION_REGEX = re.compile(r'[^\\w\\s]')\n",
        "DIGIT_REGEX = re.compile(r'\\d')\n",
        "SPECIAL_CHARACTERS_REGEX = re.compile(r'[#,@,&]')\n",
        "MULTIPLE_SPACES_REGEX = re.compile(r'\\s+')\n",
        "\n",
        "def clean_text(x: str) -> str:\n",
        "    expanded_text = contractions.fix(x)  # Expand contractions\n",
        "    text = PUNCTUATION_REGEX.sub(' ', expanded_text.lower())  # Remove punctuation after lowering\n",
        "    text = DIGIT_REGEX.sub('', text)  # Remove digits\n",
        "    # Remove special characters (#,@,&)\n",
        "    text = SPECIAL_CHARACTERS_REGEX.sub('', text)\n",
        "    # Remove multiple spaces with single space\n",
        "    text = MULTIPLE_SPACES_REGEX.sub(' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Compile regex patterns for better performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "e1142967",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'i am going to market you want to come huh'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = \"i'm going to market.you wanna come?huh?\"\n",
        "clean_text(q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "Un2OoPUTS3Mt",
      "metadata": {
        "id": "Un2OoPUTS3Mt"
      },
      "outputs": [],
      "source": [
        "counter_object_filepath = model_dir / 'counter.pkl'\n",
        "\n",
        "save_dir = Path('/content/drive/MyDrive/amazom_sentiment')\n",
        "if colab:\n",
        "    counter_object_filepath = save_dir / 'counter.pkl'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "bc8c952a",
      "metadata": {
        "id": "bc8c952a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 261828\n"
          ]
        }
      ],
      "source": [
        "# a = IntegerVectorizer(preprocessing_func=clean_text, min_freq=3) # 19 min  , contraction fix takes most of the time\n",
        "# a.adapt(df['review'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "b7uFmdEOTnKt",
      "metadata": {
        "id": "b7uFmdEOTnKt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file saved at /home/t/aproject/Amazon-review-sentiment-analysis/model/counter.pkl\n"
          ]
        }
      ],
      "source": [
        "# # save the counter object\n",
        "# counter_object = a.vocab.counter  #Vocab size: 261933\n",
        "\n",
        "# with open(counter_object_filepath, 'wb') as output_file:\n",
        "#     pickle.dump(counter_object, output_file)\n",
        "#     print('file saved at',counter_object_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "46830b95",
      "metadata": {
        "id": "46830b95"
      },
      "outputs": [],
      "source": [
        "with open(counter_object_filepath, 'rb') as output_file:\n",
        "    counter_object = pickle.load(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "3bc639ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the least common words\n",
        "least_common_words = counter_object.most_common()[::-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "sleu-ogsY4p8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sleu-ogsY4p8",
        "outputId": "9c902b40-898d-46a9-d9df-a80066894b78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('eclair', 14),\n",
              " ('krown', 14),\n",
              " ('pti', 14),\n",
              " ('winterbourne', 14),\n",
              " ('stracher', 14),\n",
              " ('zekk', 14),\n",
              " ('slection', 14),\n",
              " ('fiv', 14),\n",
              " ('kreh', 14),\n",
              " ('kaneda', 14),\n",
              " ('xhr', 14),\n",
              " ('funning', 14),\n",
              " ('guenivere', 14),\n",
              " ('aiki', 14),\n",
              " ('erring', 14),\n",
              " ('sundiver', 14),\n",
              " ('retirements', 14),\n",
              " ('carryin', 14),\n",
              " ('wfp', 14),\n",
              " ('lunt', 14),\n",
              " ('hydrangeas', 14),\n",
              " ('coombe', 14),\n",
              " ('precisa', 14),\n",
              " ('reeler', 14),\n",
              " ('sesson', 14),\n",
              " ('handsomest', 14),\n",
              " ('milimeter', 14),\n",
              " ('gastar', 14),\n",
              " ('suggestible', 14),\n",
              " ('splitted', 14),\n",
              " ('koboi', 14),\n",
              " ('kemprecos', 14),\n",
              " ('shoppin', 14),\n",
              " ('axillary', 14),\n",
              " ('brawlers', 14),\n",
              " ('whodunnits', 14),\n",
              " ('anquish', 14),\n",
              " ('convened', 14),\n",
              " ('alsoa', 14),\n",
              " ('unopen', 14),\n",
              " ('openner', 14),\n",
              " ('jomini', 14),\n",
              " ('referb', 14),\n",
              " ('gimmee', 14),\n",
              " ('inteligencia', 14),\n",
              " ('fcs', 14),\n",
              " ('gumy', 14),\n",
              " ('corrals', 14),\n",
              " ('baleful', 14),\n",
              " ('procedings', 14),\n",
              " ('chipettes', 14),\n",
              " ('highliter', 14),\n",
              " ('perfers', 14),\n",
              " ('incrdible', 14),\n",
              " ('tullock', 14),\n",
              " ('stofen', 14),\n",
              " ('boons', 14),\n",
              " ('whiskas', 14),\n",
              " ('cushings', 14),\n",
              " ('casefiles', 14),\n",
              " ('heigel', 14),\n",
              " ('sqrt', 14),\n",
              " ('getthis', 14),\n",
              " ('emir', 14),\n",
              " ('margalo', 14),\n",
              " ('cloner', 14),\n",
              " ('crocidile', 14),\n",
              " ('pulk', 14),\n",
              " ('rembered', 14),\n",
              " ('porducts', 14),\n",
              " ('oversteer', 14),\n",
              " ('multihull', 14),\n",
              " ('motet', 14),\n",
              " ('reimbursment', 14),\n",
              " ('cyric', 14),\n",
              " ('relapsed', 14),\n",
              " ('esalen', 14),\n",
              " ('daimajin', 14),\n",
              " ('centerpoint', 14),\n",
              " ('slithered', 14),\n",
              " ('deadbolts', 14),\n",
              " ('guidline', 14),\n",
              " ('pierdas', 14),\n",
              " ('spurling', 14),\n",
              " ('mustapha', 14),\n",
              " ('vsc', 14),\n",
              " ('madalyn', 14),\n",
              " ('schönberg', 14),\n",
              " ('poetica', 14),\n",
              " ('studyguide', 14),\n",
              " ('hald', 14),\n",
              " ('birn', 14),\n",
              " ('spilsbury', 14),\n",
              " ('kuper', 14),\n",
              " ('ratcliffe', 14),\n",
              " ('readthatagain', 14),\n",
              " ('simle', 14),\n",
              " ('trem', 14),\n",
              " ('erro', 14),\n",
              " ('razones', 14)]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f = 100_000\n",
        "counter_object.most_common()[f:f+100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "719ae47c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "719ae47c",
        "outputId": "0a1147eb-231a-48db-e417-8de9484d1f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                counter_object: 29.3 MiB\n",
            "            least_common_words:  6.8 MiB\n",
            "                 MultinomialNB:  1.6 KiB\n",
            "               TfidfVectorizer:  1.6 KiB\n",
            "                      Pipeline:  1.6 KiB\n",
            "                     Embedding:  1.6 KiB\n",
            "                          LSTM:  1.6 KiB\n",
            "                         Dense:  1.6 KiB\n",
            "                       Dropout:  1.6 KiB\n",
            "             TextVectorization:  1.6 KiB\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
        "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
        "        num /= 1024.0\n",
        "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
        "\n",
        "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
        "                          locals().items())), key= lambda x: -x[1], reverse = False)[:10]:\n",
        "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ec6ee32",
      "metadata": {
        "id": "9ec6ee32"
      },
      "source": [
        "# Text vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "e6f6c05a",
      "metadata": {
        "id": "e6f6c05a"
      },
      "outputs": [],
      "source": [
        "MAX_TOKEN = 100_000\n",
        "OUTPUT_SEQUENCE_LENGTH = 175  # limiting reviews to 175 words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b150ae0c",
      "metadata": {
        "id": "b150ae0c"
      },
      "source": [
        "creating a dictionary of words with counts helps me create text vectorizer alot faster .\n",
        "\n",
        "\n",
        "it only took 3min 24sec to create the dictionary from 3.6 million entries which is alot faster if you try to\n",
        "adapt  TextVectorization to the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "1771469a",
      "metadata": {
        "id": "1771469a"
      },
      "outputs": [],
      "source": [
        "text_vectorizer = TextVectorization(max_tokens=MAX_TOKEN, standardize='lower_and_strip_punctuation',\n",
        "                                   split='whitespace',\n",
        "                                    ngrams= None ,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=OUTPUT_SEQUENCE_LENGTH,\n",
        "                                    pad_to_max_tokens=True,\n",
        "                                    vocabulary = list(counter_object.keys())[:MAX_TOKEN-2]) # -2 FOR 'PAD' AND 'UNK' TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "1f9708f5",
      "metadata": {
        "id": "1f9708f5"
      },
      "outputs": [],
      "source": [
        "random_review = \"WHo the duck are you? aren't you a goose?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "489427a3",
      "metadata": {
        "id": "489427a3"
      },
      "outputs": [],
      "source": [
        "word_to_id = tf.keras.layers.StringLookup(vocabulary=text_vectorizer.get_vocabulary(), mask_token='', oov_token='[UNK]')\n",
        "id_to_word = tf.keras.layers.StringLookup(vocabulary=text_vectorizer.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "4bRul9U1Ua0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4bRul9U1Ua0c",
        "outputId": "3254f32a-6b9c-4bfe-c80d-da1a95ac0139"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'who the duck are you are not you a goose'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_text(random_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "336021c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "336021c9",
        "outputId": "a0f1afd4-1ef2-480d-ae5f-1f75b2847780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random Review:  WHo the duck are you? aren't you a goose?\n",
            "random Review length:  41\n",
            "-------\n",
            "\n",
            "vectorized review:  tf.Tensor(\n",
            "[[   91     2  8076    58    57     1    57    11 30011     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]], shape=(1, 175), dtype=int64)\n",
            "Reverse vectorized review:  tf.Tensor(\n",
            "[[b'who' b'the' b'duck' b'are' b'you' b'[UNK]' b'you' b'a' b'goose' b''\n",
            "  b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
            "  b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
            "  b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
            "  b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
            "  b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
            "  b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
            "  b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
            "  b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
            "  b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
            "  b'' b'' b'']], shape=(1, 175), dtype=string)\n",
            "-------\n",
            "\n",
            "Vocabulary_length:  100000\n",
            "Most frequent words:  ['', '[UNK]', 'the', 'best', 'soundtrack', 'ever', 'to', 'anything', 'i', 'am', 'reading', 'a', 'lot', 'of', 'reviews', 'saying', 'that', 'this', 'is', 'game', 'and', 'figured', 'would', 'write', 'review', 'disagree', 'bit', 'in', 'my', 'opinino', 'yasunori', 'mitsuda', 's', 'ultimate', 'masterpiece', 'music', 'timeless', 'been', 'listening', 'it', 'for', 'years', 'now', 'its', 'beauty', 'simply', 'refuses', 'fade', 'price', 'tag', 'on', 'pretty', 'staggering', 'must', 'say', 'but', 'if', 'you', 'are', 'going', 'buy', 'any', 'cd', 'much', 'money', 'only', 'one', 'feel', 'be', 'worth', 'every', 'penny', 'amazing', 'favorite', 'all', 'time', 'hands', 'down', 'intense', 'sadness', 'prisoners', 'fate', 'which', 'means', 'more', 'have', 'played', 'hope', 'distant', 'promise', 'girl', 'who', 'stole', 'star', 'an', 'important', 'inspiration', 'me', 'personally', 'throughout']\n",
            "least frequent words:  ['survivial', 'doria', 'atocha', 'regratably', 'apollyon', 'sharkboy', 'lavagirl', 'lautner', 'paslay', 'rolemodels']\n"
          ]
        }
      ],
      "source": [
        "print('random Review: ', random_review)\n",
        "print('random Review length: ', len(random_review))\n",
        "print('-------\\n')\n",
        "print('vectorized review: ',text_vectorizer([random_review]))\n",
        "\n",
        "print('Reverse vectorized review: ',id_to_word(text_vectorizer([random_review])))\n",
        "\n",
        "\n",
        "print('-------\\n')\n",
        "print('Vocabulary_length: ',len(text_vectorizer.get_vocabulary()))\n",
        "print('Most frequent words: ',text_vectorizer.get_vocabulary()[:100])\n",
        "print('least frequent words: ',text_vectorizer.get_vocabulary()[-10:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4d9dc6",
      "metadata": {
        "id": "fc4d9dc6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cb2beeaa",
      "metadata": {
        "id": "cb2beeaa"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8afb1b4",
      "metadata": {
        "id": "e8afb1b4"
      },
      "outputs": [],
      "source": [
        "\n",
        "TEST_SIZE = .01 # same as config.TEST_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00421d84",
      "metadata": {
        "id": "00421d84"
      },
      "outputs": [],
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split( df.select('review'), df.select('polarity'), test_size=  .01,  random_state = SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f5f852a",
      "metadata": {
        "id": "2f5f852a"
      },
      "outputs": [],
      "source": [
        "del(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46770b0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46770b0b",
        "outputId": "e5eda61d-2871-46ae-feff-4d0f9c423a4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xtrain shape (3563999, 1) ytrain shape (3563999, 1)\n",
            "xtest shape (36000, 1) ytest shape (36000, 1)\n"
          ]
        }
      ],
      "source": [
        "print('xtrain shape',xtrain.shape, 'ytrain shape', ytrain.shape)\n",
        "print('xtest shape',xtest.shape, 'ytest shape', ytest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1fdd75f",
      "metadata": {
        "id": "e1fdd75f"
      },
      "source": [
        "# Creating tensorflow dataset using `tf.data` api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "629e79dd",
      "metadata": {
        "id": "629e79dd"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58bd4829",
      "metadata": {
        "id": "58bd4829"
      },
      "outputs": [],
      "source": [
        "def data_generator(x, y):\n",
        "    num_samples = len(x)\n",
        "    for i in range(num_samples):\n",
        "        yield x[i], y[i]\n",
        "\n",
        "\n",
        "def create_datasets(x, y, text_vectorizer, batch_size, shuffle=True, buffer_size=10000):\n",
        "\n",
        "    generator = data_generator(x, y)\n",
        "    print('Generating...')\n",
        "    train_dataset = tf.data.Dataset.from_generator(\n",
        "        lambda: generator,\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(None, x.shape[1]), dtype=tf.string),\n",
        "            tf.TensorSpec(shape=(None, y.shape[1]), dtype=tf.int32)\n",
        "        )\n",
        "    )\n",
        "    print('Mapping...')\n",
        "    train_dataset = train_dataset.map(lambda x, y: (tf.cast(text_vectorizer(x), tf.int32)[0], y[0]), tf.data.AUTOTUNE)\n",
        "    train_dataset = train_dataset.batch(batch_size)\n",
        "\n",
        "    if shuffle:\n",
        "        train_dataset = train_dataset.shuffle(buffer_size)\n",
        "    train_dataset = train_dataset.cache().repeat().prefetch(tf.data.AUTOTUNE)\n",
        "    print('Done.')\n",
        "    return train_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PxF-JUhkWFU0",
      "metadata": {
        "id": "PxF-JUhkWFU0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92MKJzzfX84D",
      "metadata": {
        "id": "92MKJzzfX84D"
      },
      "outputs": [],
      "source": [
        "# ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8eb76f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8eb76f9",
        "outputId": "1ddd6c13-659c-4804-b9a6-f6711295d14a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating...\n",
            "Mapping...\n",
            "Done.\n",
            "Generating...\n",
            "Mapping...\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = create_datasets(xtrain, ytrain, text_vectorizer, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_dataset = create_datasets(xtest, ytest, text_vectorizer, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc64ea57",
      "metadata": {
        "id": "cc64ea57"
      },
      "outputs": [],
      "source": [
        "# del(xtrain, ytrain)\n",
        "# del(xtest, ytest, counter_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f557ad0b",
      "metadata": {
        "id": "f557ad0b"
      },
      "outputs": [],
      "source": [
        "# train_features = tf.data.Dataset.from_tensor_slices(xtrain)\n",
        "# train_label = tf.data.Dataset.from_tensor_slices(ytrain)\n",
        "# test_features = tf.data.Dataset.from_tensor_slices(xtest)\n",
        "# test_label = tf.data.Dataset.from_tensor_slices(ytest)\n",
        "\n",
        "# del(xtrain, ytrain, xtest, ytest) # deleting variables to free the memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cfcac6b",
      "metadata": {
        "id": "8cfcac6b"
      },
      "outputs": [],
      "source": [
        "# train_dataset = tf.data.Dataset.zip((train_features, train_label))\n",
        "# train_dataset = train_dataset.map(lambda x,y: (text_vectorizer(x)[0],y),tf.data.AUTOTUNE)\n",
        "# train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# test_dataset = tf.data.Dataset.zip((test_features, test_label))\n",
        "# test_dataset = test_dataset.map(lambda x,y: (text_vectorizer(x)[0],y),tf.data.AUTOTUNE )\n",
        "# test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# del(train_features, train_label, test_features, test_label) # deleting variables to free the memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bb2ea74",
      "metadata": {
        "id": "2bb2ea74"
      },
      "outputs": [],
      "source": [
        "# print('len train dataset: ', len(train_dataset)) # doesn't work for generator generated tensor data\n",
        "# print('len test dataset: ', len(test_dataset))  # doesn't work for generator generated tensor data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67cd8c53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67cd8c53",
        "outputId": "50deba50-c151-4475-f08c-bbe354ab78a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 175) (32, 1)\n",
            "tf.Tensor(\n",
            "[[ 9267    43  1173 ...     0     0     0]\n",
            " [   11   397   204 ...     0     0     0]\n",
            " [  236   224   417 ...     0     0     0]\n",
            " ...\n",
            " [ 1051    20    43 ...     0     0     0]\n",
            " [  415 19030     8 ...     0     0     0]\n",
            " [    1  1449    76 ...     0     0     0]], shape=(32, 175), dtype=int32) tf.Tensor(\n",
            "[[1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]], shape=(32, 1), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for i,j in train_dataset:\n",
        "    print(i.shape,j.shape)\n",
        "    print(i,j)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f99904b6",
      "metadata": {
        "id": "f99904b6"
      },
      "outputs": [],
      "source": [
        "train_length = xtrain.shape[0]// BATCH_SIZE\n",
        "test_length = xtest.shape[0] // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e76e0da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e76e0da",
        "outputId": "c64db31f-013c-49ee-fb9b-b5c7502de561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train length:  111374 \n",
            "test_length:  1125\n"
          ]
        }
      ],
      "source": [
        "print(\"train length: \", train_length, '\\ntest_length: ', test_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8afc7914",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8afc7914",
        "outputId": "7d0cf8cc-ce19-4cb9-877c-63cb7b1d5307"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PosixPath('/content/Amazon-review-sentiment-analysis/model/text_vectorizer.pkl')"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "VECTORIZER_PATH = model_dir / 'text_vectorizer.pkl'\n",
        "VECTORIZER_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f12270",
      "metadata": {
        "id": "d2f12270"
      },
      "outputs": [],
      "source": [
        "# to load text vectorizer\n",
        "def load_text_vectorizer(vectorizer_path):\n",
        "    from_disk = pickle.load(open(vectorizer_path, \"rb\"))\n",
        "    return TextVectorization.from_config(from_disk['config'])\n",
        "\n",
        "# Pickle the config and weights\n",
        "def save_text_vectorizer(vectorizer_path):\n",
        "    pickle.dump({'config': text_vectorizer.get_config()}\n",
        "                , open(vectorizer_path, \"wb\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "295c9169",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "295c9169",
        "outputId": "f1a7729b-c193-4afb-e791-61ddbe65ada6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(300000, ['', '[UNK]', 'the', 'best'])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_vectorizer.vocabulary_size(), text_vectorizer.get_vocabulary()[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a474f71",
      "metadata": {
        "id": "2a474f71"
      },
      "outputs": [],
      "source": [
        "# text_vectorizer = load_text_vectorizer(model_dir/'text_vectorizer.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lAJKVqVPZzZP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAJKVqVPZzZP",
        "outputId": "2c45b9d4-a05c-4b7f-c353-b8549d9c78bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 56M\n",
            "drwxr-xr-x 2 root root 4.0K Aug 31 10:55 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 7 root root 4.0K Aug 31 10:46 \u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1 root root  12M Aug 31 11:20 counter.pkl\n",
            "-rw-r--r-- 1 root root  44M Aug 31 10:09 text_vectorizer.pkl\n"
          ]
        }
      ],
      "source": [
        "ls -la -h ../model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68473aa6",
      "metadata": {
        "id": "68473aa6"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94fa1db9",
      "metadata": {
        "id": "94fa1db9"
      },
      "outputs": [],
      "source": [
        "save_text_vectorizer(VECTORIZER_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f2c5d8",
      "metadata": {
        "id": "d3f2c5d8"
      },
      "source": [
        "# Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54b35527",
      "metadata": {
        "id": "54b35527"
      },
      "outputs": [],
      "source": [
        "DIM = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cac4f8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cac4f8d",
        "outputId": "b61f2e3b-7414-49b4-b62d-c1e607d834a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedded text vectorized random sentence:  tf.Tensor(\n",
            "[[-0.02809688  0.03082368 -0.02951168 ... -0.01749847  0.00370653\n",
            "  -0.00014732]\n",
            " [ 0.00214576 -0.00436879 -0.04995276 ... -0.01645011 -0.03323325\n",
            "  -0.02844541]\n",
            " [ 0.04596445  0.03137359  0.04264681 ...  0.04373202  0.0074513\n",
            "  -0.03073972]\n",
            " ...\n",
            " [ 0.03726716 -0.01544239  0.02323947 ...  0.02113296  0.03661327\n",
            "  -0.0458019 ]\n",
            " [ 0.03726716 -0.01544239  0.02323947 ...  0.02113296  0.03661327\n",
            "  -0.0458019 ]\n",
            " [ 0.03726716 -0.01544239  0.02323947 ...  0.02113296  0.03661327\n",
            "  -0.0458019 ]], shape=(175, 8), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "embedding = Embedding(input_dim = MAX_TOKEN,output_dim= DIM, mask_zero=True, input_length=OUTPUT_SEQUENCE_LENGTH)\n",
        "print('Embedded text vectorized random sentence: ',embedding(text_vectorizer(random_review)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0af21ff9",
      "metadata": {
        "id": "0af21ff9"
      },
      "source": [
        "# Model:0 (Naive bayes model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c97769",
      "metadata": {
        "id": "a8c97769"
      },
      "outputs": [],
      "source": [
        "# model0 = Pipeline([\n",
        "#     ('tfidf',TfidfVectorizer()),\n",
        "#     ('multino',MultinomialNB())\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2131ed31",
      "metadata": {
        "id": "2131ed31"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# #fit and predict\n",
        "# model0.fit(xtrain['review'], ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9b520c",
      "metadata": {
        "id": "0f9b520c"
      },
      "outputs": [],
      "source": [
        "# pred0 = model0.predict(xtest['review'])\n",
        "\n",
        "# print(pred0.shape ==  ytest.shape)\n",
        "# print('pred00.shape: ',pred0.shape)\n",
        "# print('ytest.shape: ',ytest.shape)\n",
        "\n",
        "# model0_res = calculate_results(y_true=ytest, y_pred=pred0, model_name='model0: naive bayes')\n",
        "# print(model0_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adb0a7ec",
      "metadata": {
        "id": "adb0a7ec"
      },
      "source": [
        "{'model': 'model0: naive bayes', 'accuracy': 84.79444444444444, 'precision': 0.8482905354316962, 'recall': 0.8479444444444444, 'f1': 0.8479237632137091, 'discription': None}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4c5276d",
      "metadata": {
        "id": "f4c5276d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "849fff07",
      "metadata": {
        "id": "849fff07"
      },
      "source": [
        "# Model1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad696d7b",
      "metadata": {
        "id": "ad696d7b"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_lstm_model(input_shape, max_tokens, dim):\n",
        "    inputs = keras.Input(shape=(input_shape))\n",
        "    embedding_layer = Embedding(input_dim=max_tokens, output_dim=dim, mask_zero=True, input_length=input_shape, name='embedding_layer')(inputs)\n",
        "    x = LSTM(16, return_sequences=True, name = 'lstm_layer_1')(embedding_layer)\n",
        "    x = LSTM(16, name = 'lstm_layer_2')(x)\n",
        "    x = Dropout(0.4, name ='dropout_layer')(x)\n",
        "    x = Dense(64, activation='relu', name = 'dense_layer_1')(x)\n",
        "    outputs = Dense(1, activation='sigmoid', name = 'dense_layer_2_final')(x)\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name='model_lstm')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c847589e",
      "metadata": {
        "id": "c847589e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class LSTMModel(tf.keras.Model):\n",
        "    def __init__(self, text_vectorizer, embed_dim, dropout_rate=0.2):\n",
        "        super(LSTMModel, self).__init__(name='custom_lstm_model')\n",
        "        self.text_vectorizer = text_vectorizer\n",
        "\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(input_dim=text_vectorizer.vocabulary_size(), output_dim=embed_dim)\n",
        "        self.lstm1 = tf.keras.layers.LSTM(16, return_sequences=True)\n",
        "        self.lstm2 = tf.keras.layers.LSTM(16)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding_layer(inputs)\n",
        "        x = self.lstm1(x)\n",
        "        x = self.lstm2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense2(x)\n",
        "\n",
        "\n",
        "    def predict_text(self, text):\n",
        "        vectorized_text = self.text_vectorizer.transform([text])\n",
        "        return self.predict(vectorized_text)\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "output_sequence_length = OUTPUT_SEQUENCE_LENGTH  # actual value\n",
        "# model = LSTMModel(text_vectorizer, embed_dim=DIM)\n",
        "model = create_lstm_model(output_sequence_length, max_tokens=MAX_TOKEN, dim=DIM)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['Accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e538e2ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e538e2ec",
        "outputId": "82639d2f-4391-456c-a556-b351dd8cc599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 175)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 175, 8)           2400000   \n",
            "                                                                 \n",
            " lstm_layer_1 (LSTM)         (None, 175, 16)           1600      \n",
            "                                                                 \n",
            " lstm_layer_2 (LSTM)         (None, 16)                2112      \n",
            "                                                                 \n",
            " dropout_layer (Dropout)     (None, 16)                0         \n",
            "                                                                 \n",
            " dense_layer_1 (Dense)       (None, 64)                1088      \n",
            "                                                                 \n",
            " dense_layer_2_final (Dense)  (None, 1)                65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,404,865\n",
            "Trainable params: 2,404,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d49f77c2",
      "metadata": {
        "id": "d49f77c2"
      },
      "outputs": [],
      "source": [
        "# tf.keras.utils.plot_model(model, expand_nested=True, show_shapes=True, show_dtype=True, rankdir='TP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rPqCfwyaF6xx",
      "metadata": {
        "id": "rPqCfwyaF6xx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "364522a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "364522a3",
        "outputId": "bebd2e1c-7490-4169-9cd9-98de4ca1b3cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PosixPath('/content/Amazon-review-sentiment-analysis/model')"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_dir = Path(os.getcwd()).parent /'model'\n",
        "model_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IbH83I1iGaj7",
      "metadata": {
        "id": "IbH83I1iGaj7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd51a60c",
      "metadata": {
        "id": "cd51a60c"
      },
      "outputs": [],
      "source": [
        "# folder path to save the model weights\n",
        "drive_filepath = \"/content/drive/My Drive/amazom_sentiment\"\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_filepath = os.path.join(drive_filepath, \"model_weights.h5\")\n",
        "model_checkpoint_callback = ModelCheckpoint(checkpoint_filepath, monitor = 'loss', save_best_only=True, save_weights_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88cd1aa8",
      "metadata": {
        "id": "88cd1aa8"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.models.load_model(model_dir/'model.h5')\n",
        "model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2nT_DHxDIBhn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nT_DHxDIBhn",
        "outputId": "8b796162-6038-4ceb-9788-b46bb61eb80d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs          :  20\n",
            "train_length    : 111374\n",
            "test_length     :    1125\n",
            "steps_per_epoch :  5568\n",
            "validation_steps:  56\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "steps_per_epoch = int(1.0 * train_length//EPOCHS)\n",
        "validation_steps = int(1.0 * test_length//EPOCHS)\n",
        "\n",
        "print('Epochs          : ', EPOCHS)\n",
        "print('train_length    :',train_length )\n",
        "print('test_length     :   ',test_length )\n",
        "print('steps_per_epoch : ',steps_per_epoch)\n",
        "print('validation_steps: ',validation_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba48c155",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba48c155",
        "outputId": "6939d577-9647-4901-8703-2221e4bd40e0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "5568/5568 [==============================] - ETA: 0s - loss: 0.1717 - Accuracy: 0.9345"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 56 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5568/5568 [==============================] - 212s 38ms/step - loss: 0.1717 - Accuracy: 0.9345 - val_loss: 0.3289 - val_Accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "5568/5568 [==============================] - 212s 38ms/step - loss: 0.1654 - Accuracy: 0.9376\n",
            "Epoch 3/20\n",
            "5568/5568 [==============================] - 213s 38ms/step - loss: 0.1603 - Accuracy: 0.9392\n",
            "Epoch 4/20\n",
            "5568/5568 [==============================] - 212s 38ms/step - loss: 0.1580 - Accuracy: 0.9399\n",
            "Epoch 5/20\n",
            "5568/5568 [==============================] - 212s 38ms/step - loss: 0.1544 - Accuracy: 0.9418\n",
            "Epoch 6/20\n",
            "5568/5568 [==============================] - 209s 37ms/step - loss: 0.1529 - Accuracy: 0.9427\n",
            "Epoch 7/20\n",
            "5568/5568 [==============================] - 208s 37ms/step - loss: 0.1524 - Accuracy: 0.9429\n",
            "Epoch 8/20\n",
            "5568/5568 [==============================] - 210s 38ms/step - loss: 0.1492 - Accuracy: 0.9434\n",
            "Epoch 9/20\n",
            "5568/5568 [==============================] - 211s 38ms/step - loss: 0.1487 - Accuracy: 0.9434\n",
            "Epoch 10/20\n",
            "5568/5568 [==============================] - 211s 38ms/step - loss: 0.1477 - Accuracy: 0.9446\n",
            "Epoch 11/20\n",
            "5568/5568 [==============================] - 212s 38ms/step - loss: 0.1460 - Accuracy: 0.9451\n",
            "Epoch 12/20\n",
            "5568/5568 [==============================] - 214s 38ms/step - loss: 0.1471 - Accuracy: 0.9454\n",
            "Epoch 13/20\n",
            "5568/5568 [==============================] - 210s 38ms/step - loss: 0.1445 - Accuracy: 0.9465\n",
            "Epoch 14/20\n",
            "5568/5568 [==============================] - 212s 38ms/step - loss: 0.1434 - Accuracy: 0.9464\n",
            "Epoch 15/20\n",
            "5568/5568 [==============================] - 218s 39ms/step - loss: 0.1447 - Accuracy: 0.9462\n",
            "Epoch 16/20\n",
            "5568/5568 [==============================] - 206s 37ms/step - loss: 0.1435 - Accuracy: 0.9459\n",
            "Epoch 17/20\n",
            "5568/5568 [==============================] - 212s 38ms/step - loss: 0.1430 - Accuracy: 0.9467\n",
            "Epoch 18/20\n",
            "5568/5568 [==============================] - 216s 39ms/step - loss: 0.1426 - Accuracy: 0.9465\n",
            "Epoch 19/20\n",
            "   4/5568 [..............................] - ETA: 2:12 - loss: 0.0617 - Accuracy: 0.9837"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 111360 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5568/5568 [==============================] - 0s 36us/step - loss: 0.0617 - Accuracy: 0.9837\n"
          ]
        }
      ],
      "source": [
        "# %%time\n",
        "\n",
        "# fit the model\n",
        "history1 = model.fit(train_dataset, epochs = EPOCHS,\n",
        "                      validation_data= test_dataset,\n",
        "                      steps_per_epoch = steps_per_epoch,\n",
        "                      validation_steps=validation_steps,\n",
        "                     callbacks=[model_checkpoint_callback]\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb5f853",
      "metadata": {
        "id": "4bb5f853"
      },
      "outputs": [],
      "source": [
        "# model_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd80b56",
      "metadata": {
        "id": "efd80b56"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/amazom_sentiment/full_model.h5')\n",
        "# model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffdqjRAqvIQV",
      "metadata": {
        "id": "ffdqjRAqvIQV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ad33a34",
      "metadata": {
        "id": "4ad33a34"
      },
      "outputs": [],
      "source": [
        "from funcyou.plot import plot_history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a20bc95",
      "metadata": {
        "id": "4a20bc95"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D0A9yrmvssfA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0A9yrmvssfA",
        "outputId": "d853a3fc-6b84-4781-eafe-7a89eab8b5d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 175), dtype=tf.int32, name=None), TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7621b8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "d7621b8d",
        "outputId": "1e4a5bf1-8475-4ec4-bf70-f9bb6dd8ca8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "ypred1.shape:  (3,)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-f46058fb9f2d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ypred1.shape: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel1_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model1: LSTM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'small lstm model with vectorizer and embedding layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/funcyou/sklearn/metrics.py\u001b[0m in \u001b[0;36mcalculate_results\u001b[0;34m(y_true, y_pred, model_name, discription)\u001b[0m\n\u001b[1;32m     30\u001b[0m   \"\"\"\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Calculate model accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmodel_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Calculate model precision, recall and f1 score using \"weighted average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodel_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weighted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [36000, 3]"
          ]
        }
      ],
      "source": [
        "ypred = tf.squeeze(tf.round(model.predict(test_dataset)))\n",
        "print('ypred1.shape: ',ypred.shape)\n",
        "\n",
        "# model1_res = calculate_results(ytest,ypred, model_name='model1: LSTM', discription = 'small lstm model with vectorizer and embedding layer')\n",
        "# print(model1_res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22b4318b",
      "metadata": {
        "id": "22b4318b"
      },
      "outputs": [],
      "source": [
        "\n",
        "def predict_sentiment(title, text, text_vectorizer, lstm_model):\n",
        "    review = f'{title} {text}' # concatenate the title and text\n",
        "    clean_review = clean_text(review)\n",
        "    review_sequence = text_vectorizer([clean_review])\n",
        "    prediction = lstm_model.predict(review_sequence)\n",
        "    sentiment_score = prediction[0][0]\n",
        "    sentiment_label = 'Positive' if sentiment_score >= 0.5 else 'Negative'\n",
        "    return sentiment_label, sentiment_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T9EhMLJPttY2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9EhMLJPttY2",
        "outputId": "5fecd775-edb0-403c-e747-942e4ef7e723"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NBA57rbztnUv",
      "metadata": {
        "id": "NBA57rbztnUv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QMVdkWittyv-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QMVdkWittyv-",
        "outputId": "c3a5012f-f11c-4b89-8a07-bedb8835d649"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i am do not   y ll  will not'"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = \"i'm don't , y'll, won't\"\n",
        "clean_text(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39102a82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39102a82",
        "outputId": "ea743604-46aa-4030-d74c-b23d24d5a2e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 406ms/step\n",
            "Negative 0.21370934\n"
          ]
        }
      ],
      "source": [
        "review_title = 'my name is mike'\n",
        "review_text  =  \"and i don't like it\"\n",
        "\n",
        "sentiment_label, sentiment_score = predict_sentiment(review_title, review_text, text_vectorizer, model)\n",
        "print(sentiment_label, sentiment_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29833e0e",
      "metadata": {
        "id": "29833e0e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e7cb132",
      "metadata": {
        "id": "0e7cb132"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deep",
      "language": "python",
      "name": "deep"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
