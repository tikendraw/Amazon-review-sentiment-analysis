{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tikendraw/Amazon-review-sentiment-analysis/blob/main/amazon-review-sentiment-analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c16cfc6",
      "metadata": {
        "id": "1c16cfc6"
      },
      "source": [
        "# Amazon Reviews for Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fac0c72",
      "metadata": {
        "id": "3fac0c72"
      },
      "source": [
        "## Objective\n",
        "\n",
        "Here we will be Building ML and DL models to predict the Polarity of reviews.\n",
        "We will be performing series of experiments with different models to achieve the best classification metrics.(while not abusing the machine we have)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ec49b73",
      "metadata": {
        "id": "8ec49b73"
      },
      "source": [
        "## About Dataset \n",
        "[Dataset here](https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews)\n",
        "\n",
        "\n",
        "### OVERVIEW\n",
        "Contains 34,686,770 Amazon reviews from 6,643,669 users on 2,441,053 products, from the Stanford Network Analysis Project (SNAP). This subset contains 1,800,000 training samples and 200,000 testing samples in each polarity sentiment.\n",
        "\n",
        "### ORIGIN\n",
        "The Amazon reviews dataset consists of reviews from amazon. The data span a period of 18 years, including ~35 million reviews up to March 2013. Reviews include product and user information, ratings, and a plaintext review. For more information, please refer to the following paper: J. McAuley and J. Leskovec. Hidden factors and hidden topics: understanding rating dimensions with review text. RecSys, 2013.\n",
        "\n",
        "### DESCRIPTION\n",
        "The Amazon reviews polarity dataset is constructed by taking review score 1 and 2 as negative, and 4 and 5 as positive. Samples of score 3 is ignored. In the dataset, class 1 is the negative and class 2 is the positive. Each class has 1,800,000 training samples and 200,000 testing samples.\n",
        "\n",
        "If you need help extracting the train.csv and test.csv files check out the starter code.\n",
        "\n",
        "The files train.csv and test.csv contain all the training samples as comma-separated values.\n",
        "\n",
        "The CSVs contain polarity, title, text. These 3 columns in them, correspond to class index (1 or 2), review title and review text.\n",
        "\n",
        "polarity - 1 for negative and 2 for positive\n",
        "title - review heading\n",
        "text - review body\n",
        "The review title and text are escaped using double quotes (\"), and any internal double quote is escaped by 2 double quotes (\"\"). New lines are escaped by a backslash followed with an \"n\" character, that is \"\\n\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tikendraw/Amazon-review-sentiment-analysis.git\n",
        "!cd Amazon-review-sentiment-analysis"
      ],
      "metadata": {
        "id": "i5BhdkETw-pV",
        "outputId": "86eaf29b-9848-4786-ceb2-fa95b7d69c13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "i5BhdkETw-pV",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Amazon-review-sentiment-analysis'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 16 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), 394.74 KiB | 3.56 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3f06a868",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f06a868",
        "outputId": "7ea8d378-574c-48e7-e9d8-19daed9d0cbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/drive\n",
            "Tf version:  2.9.2\n",
            "GPU:  0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tensorflow.keras.layers import Embedding ,LSTM, Dense, Dropout, Conv1D, MaxPool1D, BatchNormalization, TextVectorization\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install polars -q\n",
        "import polars as pl\n",
        "!pip install wget -q\n",
        "import wget\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import tarfile\n",
        "\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "##importing useful functions\n",
        "!git clone https://github.com/tikendraw/funcyou.git -q\n",
        "\n",
        "from funcyou.metrics import calculate_results\n",
        "# from funcyou.plot import plot_history, compare_histories\n",
        "from funcyou.dataset import download_kaggle_dataset\n",
        "\n",
        "# !pip install tensorflow_hub\n",
        "\n",
        "print('Tf version: ',tf.__version__)\n",
        "print('GPU: ',gpu:= len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "os.environ[\"TFHUB_CACHE_DIR\"] = './tmp/tfhub'\n",
        "\n",
        "if gpu:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "\n",
        "use_url = 'https://storage.googleapis.com/tfhub-modules/google/universal-sentence-encoder/4.tar.gz'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_USEncoder():\n",
        "    try:\n",
        "        print('downloading universal sentence encoder...')\n",
        "        use_filename = wget.download(use_url)\n",
        "\n",
        "        print('Downloaded!')\n",
        "        # Extracting\n",
        "        os.makedirs('universal_sentence_encoder', exist_ok = True)\n",
        "        print('Extracting universal sentence encoder....')\n",
        "        # open file\n",
        "        file = tarfile.open(use_filename)\n",
        "        \n",
        "        # extracting file\n",
        "        file.extractall('./universal_sentence_encoder')\n",
        "        \n",
        "        file.close()\n",
        "        print('Extracted.')\n",
        "    except Exception as e:\n",
        "        print(e)\n"
      ],
      "metadata": {
        "id": "BC3XPV5WtRQ7"
      },
      "id": "BC3XPV5WtRQ7",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "00dd0bdb",
      "metadata": {
        "id": "00dd0bdb"
      },
      "outputs": [],
      "source": [
        "# Download the data if you don't have locally\n",
        "data_url = 'https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews'\n",
        "\n",
        "def download_data(data_url):\n",
        "    download_kaggle_dataset(url = data_url)\n",
        "    print('Dataset Downloaded.')\n",
        "\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile('./amazon-reviews.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('./dataset')\n",
        "    print('Extracted.')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "75178d33-5eca-4c81-9ccf-c0b97586e0c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75178d33-5eca-4c81-9ccf-c0b97586e0c4",
        "outputId": "37065c80-a6de-4a7d-edaf-395be886f372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n",
            "downloading universal sentence encoder...\n",
            "Downloaded!\n",
            "Extracting universal sentence encoder....\n",
            "Extracted.\n",
            "Did you upload kaggle.json?(Yes/No) y\n",
            "Dataset Downloading...\n",
            "kaggle datasets download -d kritanjalijain/amazon-reviews\n",
            "0\n",
            "Dataset Downloaded.\n",
            "Extracted.\n"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    download_USEncoder()\n",
        "    download = input('Did you upload kaggle.json?(Yes/No) ')\n",
        "    if download in ['yes','Yes','Y','y']:\n",
        "        print('Dataset Downloading...')\n",
        "        download_data(data_url)\n",
        "    \n",
        "else:\n",
        "  print('Not running on CoLab')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7ddbeaf5",
      "metadata": {
        "id": "7ddbeaf5"
      },
      "outputs": [],
      "source": [
        "embed = hub.KerasLayer(\"./universal_sentence_encoder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b0fa02",
      "metadata": {
        "id": "a5b0fa02"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "d2fc7d74",
      "metadata": {
        "id": "d2fc7d74"
      },
      "outputs": [],
      "source": [
        "#reading data\n",
        "df = pl.read_csv('./dataset/train.csv',new_columns = ['polarity', 'title','text'])  # gives TextFileReader, which is iterable with chunks of 1000 rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape: ', df.shape)\n",
        "print('Info: ',df.to_pandas().info())"
      ],
      "metadata": {
        "id": "uTCRDYo11pqM",
        "outputId": "e127c0f7-f3eb-4f0c-83cf-717977b5230b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uTCRDYo11pqM",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape:  (3599999, 3)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3599999 entries, 0 to 3599998\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Dtype \n",
            "---  ------    ----- \n",
            " 0   polarity  int64 \n",
            " 1   title     object\n",
            " 2   text      object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 82.4+ MB\n",
            "Info:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "Jsn520qsxj6C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "Jsn520qsxj6C",
        "outputId": "1887ebe0-86f5-4871-938d-8b65b4500520"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (1, 3)\n",
              "┌──────────┬───────┬──────┐\n",
              "│ polarity ┆ title ┆ text │\n",
              "│ ---      ┆ ---   ┆ ---  │\n",
              "│ u32      ┆ u32   ┆ u32  │\n",
              "╞══════════╪═══════╪══════╡\n",
              "│ 0        ┆ 0     ┆ 0    │\n",
              "└──────────┴───────┴──────┘"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        white-space: pre;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-top: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-bottom: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        line-height: 95%;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "<small>shape: (1, 3)</small>\n",
              "<thead>\n",
              "<tr>\n",
              "<th>\n",
              "polarity\n",
              "</th>\n",
              "<th>\n",
              "title\n",
              "</th>\n",
              "<th>\n",
              "text\n",
              "</th>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "u32\n",
              "</td>\n",
              "<td>\n",
              "u32\n",
              "</td>\n",
              "<td>\n",
              "u32\n",
              "</td>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# check for nulls and drop if any\n",
        "df.null_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "a0ml-HHdxvxo",
      "metadata": {
        "id": "a0ml-HHdxvxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff32ef6b-cf39-430e-e30c-a7ea575d055d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#drop nulls\n",
        "df.drop_nulls()\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_pandas().isna().sum()"
      ],
      "metadata": {
        "id": "yURUkKbf4HmS",
        "outputId": "4bf4e8fd-e995-443f-e001-115d28a6067d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yURUkKbf4HmS",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "polarity    0\n",
              "title       0\n",
              "text        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "c672dec5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "c672dec5",
        "outputId": "4d129b7d-21ad-4432-fd9c-998c0d503cc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (2, 2)\n",
              "┌──────────┬─────────┐\n",
              "│ polarity ┆ counts  │\n",
              "│ ---      ┆ ---     │\n",
              "│ i64      ┆ u32     │\n",
              "╞══════════╪═════════╡\n",
              "│ 2        ┆ 1799999 │\n",
              "│ 1        ┆ 1800000 │\n",
              "└──────────┴─────────┘"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        white-space: pre;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-top: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-bottom: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        line-height: 95%;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "<small>shape: (2, 2)</small>\n",
              "<thead>\n",
              "<tr>\n",
              "<th>\n",
              "polarity\n",
              "</th>\n",
              "<th>\n",
              "counts\n",
              "</th>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "i64\n",
              "</td>\n",
              "<td>\n",
              "u32\n",
              "</td>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "<td>\n",
              "1799999\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "<td>\n",
              "1800000\n",
              "</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# checking for classs imbalance\n",
        "df['polarity'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13db8966",
      "metadata": {
        "id": "13db8966"
      },
      "source": [
        "**Note:** The dataset is fairly large, we will use tensorflow's data api to load and handle the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c168d8cf",
      "metadata": {
        "id": "c168d8cf"
      },
      "source": [
        "# We will map the polarity between 0 for negative sentiment to 1 for positive sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "f5cac18d",
      "metadata": {
        "id": "f5cac18d"
      },
      "outputs": [],
      "source": [
        "df = df.with_columns([\n",
        "                    # pl.col('polarity').apply(lambda x: 0 if x == 1 else 1).alias('polarity'),\n",
        "                     pl.col('polarity').cast(pl.Int16, strict=False).alias('polarity')\n",
        "                     ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "be973a53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "be973a53",
        "outputId": "a9e6b43f-6784-42bd-acd2-bd69e5ec9463"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (10, 3)\n",
              "┌──────────┬─────────────────────────────────────┬─────────────────────────────────────┐\n",
              "│ polarity ┆ title                               ┆ text                                │\n",
              "│ ---      ┆ ---                                 ┆ ---                                 │\n",
              "│ i16      ┆ str                                 ┆ str                                 │\n",
              "╞══════════╪═════════════════════════════════════╪═════════════════════════════════════╡\n",
              "│ 1        ┆ Horrifying                          ┆ This book is criminal. Please re... │\n",
              "│ 1        ┆ What's This! MetalHeads Don't Ne... ┆ It's obvious that Saliva has not... │\n",
              "│ 1        ┆ John Grisham, The Partner           ┆ Very slow moving and uninteresti... │\n",
              "│ 2        ┆ Pleased furry customers             ┆ Our cats absolutely love these b... │\n",
              "│ ...      ┆ ...                                 ┆ ...                                 │\n",
              "│ 2        ┆ Stephen King's \"Andromeda Strain... ┆ Michael Crichton's \"Andromeda St... │\n",
              "│ 1        ┆ Horrible                            ┆ I was expecting these to be gum,... │\n",
              "│ 2        ┆ Definitive early Van Ronk collec... ┆ If you appreciate the late Dave ... │\n",
              "│ 1        ┆ Author has no clue                  ┆ We live with farm animals and kn... │\n",
              "└──────────┴─────────────────────────────────────┴─────────────────────────────────────┘"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        white-space: pre;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-top: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-bottom: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        line-height: 95%;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "<small>shape: (10, 3)</small>\n",
              "<thead>\n",
              "<tr>\n",
              "<th>\n",
              "polarity\n",
              "</th>\n",
              "<th>\n",
              "title\n",
              "</th>\n",
              "<th>\n",
              "text\n",
              "</th>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "i16\n",
              "</td>\n",
              "<td>\n",
              "str\n",
              "</td>\n",
              "<td>\n",
              "str\n",
              "</td>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "<td>\n",
              "&quot;Horrifying&quot;\n",
              "</td>\n",
              "<td>\n",
              "&quot;This book is c...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "<td>\n",
              "&quot;What&#x27;s This! M...\n",
              "</td>\n",
              "<td>\n",
              "&quot;It&#x27;s obvious t...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "<td>\n",
              "&quot;John Grisham, ...\n",
              "</td>\n",
              "<td>\n",
              "&quot;Very slow movi...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "<td>\n",
              "&quot;Pleased furry ...\n",
              "</td>\n",
              "<td>\n",
              "&quot;Our cats absol...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "<td>\n",
              "&quot;Poor audio qua...\n",
              "</td>\n",
              "<td>\n",
              "&quot;I have a Panas...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "<td>\n",
              "&quot;AWESOME!!!&quot;\n",
              "</td>\n",
              "<td>\n",
              "&quot;Excellent valu...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "<td>\n",
              "&quot;Stephen King&#x27;s...\n",
              "</td>\n",
              "<td>\n",
              "&quot;Michael Cricht...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "<td>\n",
              "&quot;Horrible&quot;\n",
              "</td>\n",
              "<td>\n",
              "&quot;I was expectin...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "<td>\n",
              "&quot;Definitive ear...\n",
              "</td>\n",
              "<td>\n",
              "&quot;If you appreci...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "<td>\n",
              "&quot;Author has no ...\n",
              "</td>\n",
              "<td>\n",
              "&quot;We live with f...\n",
              "</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de08710a",
      "metadata": {
        "id": "de08710a"
      },
      "source": [
        "## Note: We will be combining text and title columns . makes more sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "cfa3949d",
      "metadata": {
        "id": "cfa3949d"
      },
      "outputs": [],
      "source": [
        "#preprocessing functions to clear punctuations, lower strings, remove special chars removing contractions\n",
        "from funcyou.preprocessing.text import  text_cleaning_apos, cont_to_exp, text_cleaning\n",
        "\n",
        "\n",
        "def clean_all(text):\n",
        "    text = text_cleaning_apos(text)\n",
        "    text = cont_to_exp(text)\n",
        "    text = text_cleaning(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "26892e90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26892e90",
        "outputId": "b7dd14a9-8944-4dc9-ef1b-aa37f1e9a706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 965 ms, sys: 2.33 s, total: 3.3 s\n",
            "Wall time: 3.36 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# with pandas\n",
        "# print('Started at: ',datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
        "# print('This cell takes 10 minutes to process 3.6M data')\n",
        "# #joining columns and cleaning the text \n",
        "# df['review'] = df['title']+' ' + df['text']\n",
        "# # df['review'] = df['review'].apply(clean_all)\n",
        "# df['review'] = df['review'].astype(np.object_)\n",
        "\n",
        "\n",
        "df = df.with_columns([\n",
        "    (pl.col('title')+' ' + pl.col('text')).alias('review')\n",
        "])\n",
        "\n",
        "# df['review'] = df['review'].apply(clean_all)\n",
        "# df['review'] = df['review'].astype(np.object_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O9mHCcldyNVP",
      "metadata": {
        "id": "O9mHCcldyNVP"
      },
      "outputs": [],
      "source": [
        "df.review.sample(1).values.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "419c7412",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "419c7412",
        "outputId": "7faae89d-696d-48db-a85f-2b50a757014e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (10, 4)\n",
              "┌──────────┬─────────────────────────────┬────────────────────────────┬────────────────────────────┐\n",
              "│ polarity ┆ title                       ┆ text                       ┆ review                     │\n",
              "│ ---      ┆ ---                         ┆ ---                        ┆ ---                        │\n",
              "│ i16      ┆ str                         ┆ str                        ┆ str                        │\n",
              "╞══════════╪═════════════════════════════╪════════════════════════════╪════════════════════════════╡\n",
              "│ 2        ┆ best disney princess dolls  ┆ this dolls is very         ┆ best disney princess dolls │\n",
              "│          ┆                             ┆ beautiful. sh...           ┆ this ...                   │\n",
              "│ 2        ┆ Use it as a guide, but not  ┆ Use it as a guide, but not ┆ Use it as a guide, but not │\n",
              "│          ┆ exclu...                    ┆ exclu...                   ┆ exclu...                   │\n",
              "│ 2        ┆ Its not the best but its    ┆ I really Love Sailor Moon! ┆ Its not the best but its   │\n",
              "│          ┆ good!                       ┆ I got...                   ┆ good! I...                 │\n",
              "│ 1        ┆ Disappointed                ┆ Very disappointed - with   ┆ Disappointed Very          │\n",
              "│          ┆                             ┆ the cas...                 ┆ disappointed -...          │\n",
              "│ ...      ┆ ...                         ┆ ...                        ┆ ...                        │\n",
              "│ 2        ┆ For what i payed            ┆ I wasn't too disappointed. ┆ For what i payed I wasn't  │\n",
              "│          ┆                             ┆ Reall...                   ┆ too di...                  │\n",
              "│ 1        ┆ Girls gone wild...          ┆ This really looks like a   ┆ Girls gone wild... This    │\n",
              "│          ┆                             ┆ hoochie...                 ┆ really l...                │\n",
              "│ 1        ┆ Tex Mex Cookbook by Robb    ┆ Robb Walsh's Tex-Mex       ┆ Tex Mex Cookbook by Robb   │\n",
              "│          ┆ Walsh                       ┆ Cookbook is...             ┆ Walsh R...                 │\n",
              "│ 2        ┆ the best storage for your   ┆ I bought one of these      ┆ the best storage for your  │\n",
              "│          ┆ beauty...                   ┆ years ago,...              ┆ beauty...                  │\n",
              "└──────────┴─────────────────────────────┴────────────────────────────┴────────────────────────────┘"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        white-space: pre;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-top: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-bottom: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        line-height: 95%;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "<small>shape: (10, 4)</small>\n",
              "<thead>\n",
              "<tr>\n",
              "<th>\n",
              "polarity\n",
              "</th>\n",
              "<th>\n",
              "title\n",
              "</th>\n",
              "<th>\n",
              "text\n",
              "</th>\n",
              "<th>\n",
              "review\n",
              "</th>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "i16\n",
              "</td>\n",
              "<td>\n",
              "str\n",
              "</td>\n",
              "<td>\n",
              "str\n",
              "</td>\n",
              "<td>\n",
              "str\n",
              "</td>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "<td>\n",
              "&quot;best disney pr...\n",
              "</td>\n",
              "<td>\n",
              "&quot;this dolls is ...\n",
              "</td>\n",
              "<td>\n",
              "&quot;best disney pr...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "<td>\n",
              "&quot;Use it as a gu...\n",
              "</td>\n",
              "<td>\n",
              "&quot;Use it as a gu...\n",
              "</td>\n",
              "<td>\n",
              "&quot;Use it as a gu...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "<td>\n",
              "&quot;Its not the be...\n",
              "</td>\n",
              "<td>\n",
              "&quot;I really Love ...\n",
              "</td>\n",
              "<td>\n",
              "&quot;Its not the be...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "<td>\n",
              "&quot;Disappointed&quot;\n",
              "</td>\n",
              "<td>\n",
              "&quot;Very disappoin...\n",
              "</td>\n",
              "<td>\n",
              "&quot;Disappointed V...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "<td>\n",
              "&quot;vanilla beans&quot;\n",
              "</td>\n",
              "<td>\n",
              "&quot;I bought these...\n",
              "</td>\n",
              "<td>\n",
              "&quot;vanilla beans ...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "<td>\n",
              "&quot;Well produced,...\n",
              "</td>\n",
              "<td>\n",
              "&quot;The good news ...\n",
              "</td>\n",
              "<td>\n",
              "&quot;Well produced,...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "<td>\n",
              "&quot;For what i pay...\n",
              "</td>\n",
              "<td>\n",
              "&quot;I wasn&#x27;t too d...\n",
              "</td>\n",
              "<td>\n",
              "&quot;For what i pay...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "<td>\n",
              "&quot;Girls gone wil...\n",
              "</td>\n",
              "<td>\n",
              "&quot;This really lo...\n",
              "</td>\n",
              "<td>\n",
              "&quot;Girls gone wil...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "<td>\n",
              "&quot;Tex Mex Cookbo...\n",
              "</td>\n",
              "<td>\n",
              "&quot;Robb Walsh&#x27;s T...\n",
              "</td>\n",
              "<td>\n",
              "&quot;Tex Mex Cookbo...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "<td>\n",
              "&quot;the best stora...\n",
              "</td>\n",
              "<td>\n",
              "&quot;I bought one o...\n",
              "</td>\n",
              "<td>\n",
              "&quot;the best stora...\n",
              "</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c231647e",
      "metadata": {
        "id": "c231647e"
      },
      "source": [
        "A dataframe to store results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445aac9f",
      "metadata": {
        "id": "445aac9f"
      },
      "outputs": [],
      "source": [
        "#creating a dataframe to store results\n",
        "all_result = pd.DataFrame(columns=['model','accuracy','precision','recall','f1','discription'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9301f9e0",
      "metadata": {
        "id": "9301f9e0"
      },
      "outputs": [],
      "source": [
        "def add_to_big_result(res:dict):\n",
        "    global all_result\n",
        "    res = pd.DataFrame([res])\n",
        "    all_result = pd.concat([all_result, res], ignore_index=True)\n",
        "    print(all_result)\n",
        "    return all_result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8-MfHWr8vVq6",
      "metadata": {
        "id": "8-MfHWr8vVq6"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0611993",
      "metadata": {
        "id": "b0611993"
      },
      "outputs": [],
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split( df[['review']], df['polarity'], test_size=  .001, stratify=df['polarity'], random_state = 89)\n",
        "xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=  .05, stratify=ytrain,random_state = 89)\n",
        "\n",
        "print('xtrain shape',xtrain.shape, 'ytrain shape', ytrain.shape)\n",
        "print('xtest shape',xtest.shape, 'ytest shape', ytest.shape)\n",
        "print('xval shape',xval.shape, 'yval shape', yval.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c9ea8eb",
      "metadata": {
        "id": "3c9ea8eb"
      },
      "outputs": [],
      "source": [
        "del(df) # deleting variables to keep the memory free\n",
        "xtrain.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d479ed60",
      "metadata": {
        "id": "d479ed60"
      },
      "outputs": [],
      "source": [
        "xtrain.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6c94f11",
      "metadata": {
        "id": "a6c94f11"
      },
      "outputs": [],
      "source": [
        "ytrain.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9c7fbc7",
      "metadata": {
        "id": "d9c7fbc7"
      },
      "source": [
        "# Creating tensorflow dataset using `tf.data` api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AYPRoiWsxXHj",
      "metadata": {
        "id": "AYPRoiWsxXHj"
      },
      "outputs": [],
      "source": [
        "xtrain.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec8934c4",
      "metadata": {
        "id": "ec8934c4"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "#train\n",
        "train_feature = tf.data.Dataset.from_tensor_slices(xtrain)\n",
        "train_label = tf.data.Dataset.from_tensor_slices(ytrain)\n",
        "#test\n",
        "test_feature = tf.data.Dataset.from_tensor_slices(xtest)\n",
        "test_label = tf.data.Dataset.from_tensor_slices(ytest)\n",
        "#val\n",
        "val_feature = tf.data.Dataset.from_tensor_slices(xval)\n",
        "val_label = tf.data.Dataset.from_tensor_slices(yval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4504403",
      "metadata": {
        "id": "d4504403"
      },
      "outputs": [],
      "source": [
        "for i in train_feature.take(1):\n",
        "    print(i)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd6e6900",
      "metadata": {
        "id": "cd6e6900"
      },
      "outputs": [],
      "source": [
        "for i in train_label.take(1):\n",
        "    print(i)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6ab310",
      "metadata": {
        "id": "af6ab310"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "train_dataset = tf.data.Dataset.zip((train_feature, train_label))\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.zip((test_feature, test_label))\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.zip((val_feature, val_label))\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JqBZ_Wey4q-w",
      "metadata": {
        "id": "JqBZ_Wey4q-w"
      },
      "outputs": [],
      "source": [
        "del(train_feature, train_label, test_feature, test_label, val_feature, val_label) # deleting variables to keep the memory free"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c1c1e7",
      "metadata": {
        "id": "67c1c1e7"
      },
      "outputs": [],
      "source": [
        "print('len train dataset: ', len(train_dataset))\n",
        "print('len test dataset: ', len(test_dataset))\n",
        "print('len val dataset: ', len(val_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07f71ed4",
      "metadata": {
        "id": "07f71ed4"
      },
      "source": [
        "# Model:0 (Naive bayes model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a84f9490",
      "metadata": {
        "id": "a84f9490"
      },
      "outputs": [],
      "source": [
        "model0 = Pipeline([\n",
        "    ('tfidf',TfidfVectorizer()),\n",
        "    ('multino',MultinomialNB())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64586ad7",
      "metadata": {
        "id": "64586ad7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#fit and predict\n",
        "# model0.fit(xtrain['review'], ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0e8c64",
      "metadata": {
        "id": "8c0e8c64"
      },
      "outputs": [],
      "source": [
        "# pred0 = model0.predict(xtest['review'])\n",
        "\n",
        "# print(pred0.shape ==  ytest.shape)\n",
        "# print('pred00.shape: ',pred0.shape)\n",
        "# print('ytest.shape: ',ytest.shape)\n",
        "\n",
        "# model0_res = calculate_results(y_true=ytest, y_pred=pred0, model_name='model0: naive bayes')\n",
        "# print(model0_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24413776",
      "metadata": {
        "id": "24413776"
      },
      "outputs": [],
      "source": [
        "# preditions on texts is more accurate than titles, simply because there is more words and combinations which describes the sentiments better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7058f66c",
      "metadata": {
        "id": "7058f66c"
      },
      "outputs": [],
      "source": [
        "# all_result =add_to_big_result(model0_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed25181b",
      "metadata": {
        "id": "ed25181b"
      },
      "source": [
        "# Text vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a023364",
      "metadata": {
        "id": "8a023364"
      },
      "outputs": [],
      "source": [
        "# MAX_TOKEN = 1_00_00\n",
        "# OUTPUT_SEQUENCE_LENGTH = 200  # limiting reviews to 200 words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7298be63",
      "metadata": {
        "id": "7298be63"
      },
      "outputs": [],
      "source": [
        "# text_vectorizer = TextVectorization(max_tokens=MAX_TOKEN, standardize='lower_and_strip_punctuation',\n",
        "#                                    split='whitespace',\n",
        "#                                     ngrams= None ,\n",
        "#                                     output_mode='int',\n",
        "#                                     output_sequence_length=OUTPUT_SEQUENCE_LENGTH, \n",
        "#                                     pad_to_max_tokens=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e38d4f",
      "metadata": {
        "id": "f3e38d4f"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# #adapting to training data\n",
        "# print(\"cell takes: \")\n",
        "# text_vectorizer.adapt(train_feature)\n",
        "\n",
        "# random_review = df['review'].sample(n = 1).values\n",
        "# print('random Review: ', random_review)\n",
        "# print('random Review length: ', len(random_review))\n",
        "# print('-------\\n')\n",
        "# print('vectorized review: ',text_vectorizer(random_review))\n",
        "# print('-------\\n')\n",
        "# print('Vocabulary_length: ',len(text_vectorizer.get_vocabulary()))\n",
        "# print('Most frequent words: ',text_vectorizer.get_vocabulary()[:10])\n",
        "# print('least frequent words: ',text_vectorizer.get_vocabulary()[-10:])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f2c5d8",
      "metadata": {
        "id": "d3f2c5d8"
      },
      "source": [
        "# Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cac4f8d",
      "metadata": {
        "id": "4cac4f8d"
      },
      "outputs": [],
      "source": [
        "# embedding = Embedding(input_dim = MAX_TOKEN,output_dim= 32, mask_zero=True, input_length=OUTPUT_SEQUENCE_LENGTH)\n",
        "# print('Embedded text vectorized random sentence: ',embedding(text_vectorizer(random_review)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "849fff07",
      "metadata": {
        "id": "849fff07"
      },
      "source": [
        "# Model1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c847589e",
      "metadata": {
        "id": "c847589e"
      },
      "outputs": [],
      "source": [
        "# inputs  = keras.Input(shape= (1), dtype = tf.string)\n",
        "# vectorizer_layer  = text_vectorizer(inputs)\n",
        "# embedding_layer  = embedding(vectorizer_layer)\n",
        "\n",
        "# x = LSTM(16, return_sequences=True)(embedding_layer)\n",
        "# # x = LSTM(32, return_sequences=True)(x)\n",
        "# x = LSTM(16)(x)\n",
        "# x = Dropout(.4)(x)\n",
        "# x = Dense(64, activation='relu')(x)\n",
        "# outputs = Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "# #building model\n",
        "# model1 = keras.Model(inputs = inputs, outputs = outputs, name = 'model1_lstm')\n",
        "\n",
        "# #compiling model\n",
        "# model1.compile(loss = keras.losses.binary_crossentropy,\n",
        "#               optimizer = keras.optimizers.Adam(),\n",
        "#               metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a76eff94",
      "metadata": {
        "id": "a76eff94"
      },
      "outputs": [],
      "source": [
        "# EPOCHS = 5\n",
        "# print(len(train_dataset), len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba48c155",
      "metadata": {
        "id": "ba48c155",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "\n",
        "#fit the model\n",
        "# history1 = model1.fit(train_dataset, epochs = EPOCHS, \n",
        "#                       validation_data= val_dataset, \n",
        "#                       steps_per_epoch=int(.1*(len(train_dataset) / EPOCHS)),\n",
        "#                       validation_steps=int(.1*(len(val_dataset) / EPOCHS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1928d1cf",
      "metadata": {
        "cellView": "form",
        "id": "1928d1cf"
      },
      "outputs": [],
      "source": [
        "#@title Plot history function\n",
        "def plot_history1(history, plot = ['loss','accuracy'], split = ['train','val'], epoch:int = None, figsize = (20,10),colors = ['r','b'], **plot_kwargs ):\n",
        "    \n",
        "    ''' Plots History\n",
        "\n",
        "    Arguments:\n",
        "    ###############\n",
        "    histroy \t:\tHistory to plot\n",
        "    plot:list\t:   what to plot (what metrics you want to compare)  -> ['loss', 'accuracy']  \n",
        "    split:list  :   what split to compare -> ['train', 'val']\n",
        "    epoch:int   :   for how many epochs to comapre (cannot be greater than highest epoch of histories)\n",
        "    figsize:tuple:  size of plot\n",
        "    plot_kwargs :   kwargs to plt.plot to customize plot\n",
        "\n",
        "    Returns:\n",
        "    ##############\n",
        "    Plots history \n",
        "\n",
        "    '''\n",
        "\n",
        "    try:\n",
        "        import matplotlib as mpl\n",
        "        mpl.rcParams['figure.dpi'] = 500\n",
        "        \n",
        "        if not len(colors) == len(split):\n",
        "            raise ValueError('not enogh colors')\n",
        "        \n",
        "        cols = []\n",
        "        for i in plot:\n",
        "            for j in split:\n",
        "                if j == 'val':\n",
        "                    cols.append(j+'_'+i)\n",
        "                else:\n",
        "                    cols.append(i)\n",
        "        \n",
        "        #compare to epoch\n",
        "        if epoch is None:\n",
        "            epoch = history.epoch\n",
        "\n",
        "        def display(col, plot_num, history, epoch:int = None,label = None, **plot_kwargs):\n",
        "            plt.subplot(len(plot),len(split),plot_num)\n",
        "            plt.grid(True)\n",
        "            \n",
        "            if epoch == None:\n",
        "                epoch = history.epoch\n",
        "            \n",
        "            if label is None:\n",
        "                label=history.model.name\n",
        "                \n",
        "            plt.plot(epoch, pd.DataFrame(history.history)[col], label=label, **plot_kwargs)\n",
        "            plt.title((' '.join(col.split('_'))).upper())\n",
        "            plt.xlabel('epochs')\n",
        "            plt.legend()\n",
        "        \n",
        "        plt.figure(figsize = figsize)\n",
        "        plot_title = \" \".join(plot).upper()+\" PLOT\"\n",
        "        plt.suptitle(plot_title)\n",
        "\n",
        "        for plot_num,col in enumerate(plot,1):\n",
        "            display(col, plot_num, history, epoch, label = 'train',color = colors[0], **plot_kwargs)\n",
        "            if 'val' in split:\n",
        "                display('val_'+col, plot_num, history, epoch,label = 'val' ,color = colors[1])\n",
        "    except Exception as e:\n",
        "        print('Error Occured: ',e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "863cb15c",
      "metadata": {
        "id": "863cb15c"
      },
      "outputs": [],
      "source": [
        "#plot history\n",
        "# plot_history1(history1, plot=['loss','accuracy'], figsize=(15,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a20bc95",
      "metadata": {
        "id": "4a20bc95"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7621b8d",
      "metadata": {
        "id": "d7621b8d"
      },
      "outputs": [],
      "source": [
        "# ypred1 = tf.squeeze(tf.round(model1.predict(xtest)))\n",
        "# print('ypred1.shape: ',ypred1.shape)\n",
        "\n",
        "# model1_res = calculate_results(ytest,ypred1, model_name='model1: LSTM', discription = 'small lstm model with vectorizer and embedding layer')\n",
        "# print(model1_res)\n",
        "\n",
        "## adding result to all_result \n",
        "# all_result = add_to_big_result(model1_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8cc4a52",
      "metadata": {
        "id": "c8cc4a52"
      },
      "source": [
        "#### saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "486f4c5b",
      "metadata": {
        "id": "486f4c5b"
      },
      "outputs": [],
      "source": [
        "# model2.save('./drive/MyDrive/amazon_review/saved_models/model2_lstm_use_layer.tf', save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "961af382",
      "metadata": {
        "id": "961af382"
      },
      "outputs": [],
      "source": [
        "#load the saved model\n",
        "# model1_loaded = keras.models.load_model('./saved_models/model1_lstm.tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4bee255",
      "metadata": {
        "id": "d4bee255"
      },
      "outputs": [],
      "source": [
        "# ypred11 = tf.squeeze(tf.round(model1_loaded.predict(xtest)))\n",
        "# model11_res = calculate_results(ytest,ypred11, model_name='model1: LSTM loaded')\n",
        "# print(model11_res)\n",
        "# all_result = add_to_big_result(model11_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9880352",
      "metadata": {
        "id": "c9880352"
      },
      "source": [
        "# Model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c493fe37",
      "metadata": {
        "id": "c493fe37"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape = [], dtype = 'string')\n",
        "use_layer = embed(inputs)\n",
        "print(use_layer.shape)\n",
        "use_layer = tf.expand_dims(use_layer, axis = 1)\n",
        "print(use_layer.shape) \n",
        "x = LSTM(32, return_sequences=True)(use_layer)\n",
        "# x = LSTM(32, return_sequences=True)(x)\n",
        "x = LSTM(16)(x)\n",
        "x = Dropout(.4)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "outputs = Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "#building model\n",
        "model2 = keras.Model(inputs = inputs, outputs = outputs, name = 'model2_use_layer')\n",
        "\n",
        "#compiling model\n",
        "model2.compile(loss = keras.losses.binary_crossentropy,\n",
        "              optimizer = keras.optimizers.Adam(),\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d457c6f",
      "metadata": {
        "id": "9d457c6f"
      },
      "outputs": [],
      "source": [
        "# from funcyou.callbacks import create_model_checkpoint\n",
        "def create_model_checkpoint(model_name, save_dir, monitor:str = 'val_loss',verbose: int = 0, save_best_only: bool = True, save_weights_only: bool = False,\n",
        "                            mode: str = 'auto', save_freq='epoch', options=None, initial_value_threshold=None, **kwargs):\n",
        "    model_name = model_name+'-'+ str(datetime.datetime.now())\n",
        "    dir = os.path.join(save_dir, model_name)\n",
        "\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "    return tf.keras.callbacks.ModelCheckpoint(\n",
        "                                                dir,\n",
        "                                                monitor = monitor,\n",
        "                                                verbose = verbose,\n",
        "                                                save_best_only = save_best_only,\n",
        "                                                save_weights_only = save_weights_only,\n",
        "                                                mode = mode,\n",
        "                                                save_freq = save_freq,\n",
        "                                                options=options,\n",
        "                                                initial_value_threshold = initial_value_threshold,\n",
        "                                                **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd56b05",
      "metadata": {
        "id": "5cd56b05"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "print(len(train_dataset), len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9S57Eof77O_Z",
      "metadata": {
        "id": "9S57Eof77O_Z"
      },
      "outputs": [],
      "source": [
        "# del(train_dataset, test_dataset, val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7200cc9",
      "metadata": {
        "id": "d7200cc9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# #fit the model\n",
        "# history2 = model2.fit(train_dataset, epochs = EPOCHS, \n",
        "#                       validation_data= val_dataset, \n",
        "#                       steps_per_epoch=int((len(train_dataset) / EPOCHS)),\n",
        "#                       validation_steps=int(1*(len(val_dataset) / EPOCHS)),\n",
        "#                       callbacks = [\n",
        "#                                     create_model_checkpoint(model_name = 'model2:use_lstm', \n",
        "#                                     save_dir = '/content/drive/MyDrive/amazon_review/', \n",
        "#                                     monitor = 'val_accuracy',\n",
        "#                                     save_best_only = True, \n",
        "#                                     save_weights_only = True,\n",
        "#                                         mode= 'auto', save_freq='epoch')]\n",
        "#                       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d804996",
      "metadata": {
        "id": "7d804996"
      },
      "outputs": [],
      "source": [
        "# plot_history\n",
        "# plot_history1(history2, plot=['loss','accuracy'], figsize=(15,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2sifKPOGCHX9",
      "metadata": {
        "id": "2sifKPOGCHX9"
      },
      "outputs": [],
      "source": [
        "model2.load_weights('./amazon_review-20221127T193218Z-001/amazon_review/model2_use_lstm-2022-11-27 06_40_52.876175')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2401f31a",
      "metadata": {
        "id": "2401f31a"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a15ff1",
      "metadata": {
        "id": "36a15ff1"
      },
      "outputs": [],
      "source": [
        "ypred2 = tf.squeeze(tf.round(model2.predict(test_dataset,\n",
        "                                            use_multiprocessing=True)))\n",
        "print('ypred2.shape: ',ypred2.shape)\n",
        "\n",
        "ytest_true = [y for x,y in test_dataset.unbatch()]\n",
        "print('ypred2.shape: ',len(ytest_true))\n",
        "\n",
        "model2_res = calculate_results(np.array(ytest_true),ypred2, model_name='model2: use layer lstm')\n",
        "print('model2_res: ',model2_res)\n",
        "\n",
        "all_result = add_to_big_result(model2_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7KSp4D2REBKv",
      "metadata": {
        "id": "7KSp4D2REBKv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Msk2u4kXDl2U",
      "metadata": {
        "id": "Msk2u4kXDl2U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c27e488d",
      "metadata": {
        "id": "c27e488d"
      },
      "source": [
        "# Model3: Conv1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UVCl0QMIFAgO",
      "metadata": {
        "id": "UVCl0QMIFAgO"
      },
      "outputs": [],
      "source": [
        "inputs = layers.Input(shape=(1,), dtype = 'string')\n",
        "vect_layer = text_vectorizer(inputs)\n",
        "embed_layer = embed(vect_layer)\n",
        "x = layers.Conv1D(64,3,1,padding = 'same',activation = 'relu')(embed_layer)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.MaxPooling1D()(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(5, activation = 'softmax')(x)\n",
        "\n",
        "\n",
        "inputs = keras.Input(shape = [], dtype = 'string')\n",
        "use_layer = embed(inputs)\n",
        "print(use_layer.shape)\n",
        "use_layer = tf.expand_dims(use_layer, axis = 1)\n",
        "print(use_layer.shape) \n",
        "x = LSTM(32, return_sequences=True)(use_layer)\n",
        "# x = LSTM(32, return_sequences=True)(x)\n",
        "x = LSTM(16)(x)\n",
        "x = Dropout(.4)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "outputs = Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "#building model\n",
        "model2 = keras.Model(inputs = inputs, outputs = outputs, name = 'model2_use_layer')\n",
        "\n",
        "#compiling model\n",
        "model2.compile(loss = keras.losses.binary_crossentropy,\n",
        "              optimizer = keras.optimizers.Adam(),\n",
        "              metrics = ['accuracy'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tf_new",
      "language": "python",
      "name": "tf_new"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}